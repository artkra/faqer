{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to ./data/...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /home/artkra/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "nltk.data.path.append('./data')\n",
    "nltk.download('stopwords', './data/')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c = Counter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/slack/messages.txt', 'r') as fr:\n",
    "    with open('../../data/slack/tokens.txt', 'w') as fw:\n",
    "        for line in fr.readlines():\n",
    "            if '?' in line:\n",
    "                tokens = [w.lower() for w in nltk.tokenize.word_tokenize(line) if w.isalpha()]\n",
    "                tokens = [w for w in tokens if w not in nltk.corpus.stopwords.words('russian')]\n",
    "                tokens = [w for w in tokens if w not in nltk.corpus.stopwords.words('english')]\n",
    "                c += Counter(tokens)\n",
    "                fw.write(','.join(tokens) + '\\n')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "WORDS = []\n",
    "for i, word in enumerate(sorted(c, key=lambda x: c[x], reverse=True)):\n",
    "    X.append(i)\n",
    "    WORDS.append(word)\n",
    "    Y.append(c[word])\n",
    "plt.plot(X, Y, marker='o')\n",
    "plt.xlim([0, 20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "YSHIFTED = copy(Y)\n",
    "YSHIFTED = YSHIFTED[1::]\n",
    "YSHIFTED.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIFFS = np.array(Y) - np.array(YSHIFTED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f57d1b75528>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text():\n",
    "    with open('../../data/slack/messages.txt', 'r') as fr:\n",
    "        return fr.read()\n",
    "\n",
    "\n",
    "def tokenize_text(text):\n",
    "    def to_include(word):\n",
    "        if any([\n",
    "            not word.isalpha(),\n",
    "            word in nltk.corpus.stopwords.words('russian'),\n",
    "            word in nltk.corpus.stopwords.words('english')\n",
    "        ]):\n",
    "            return False\n",
    "        return True\n",
    "    tokens = [w.lower() for w in nltk.tokenize.word_tokenize(text) if to_include(w)]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def count_freq(tokens):\n",
    "    c = Counter(tokens)\n",
    "    return sorted(c, key=lambda x: c[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS = tokenize_text(get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Counter(TOKENS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-fa11b8f03811>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# Step 5. Do the backward pass and update the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/faqer-EGfSzUrq-py3.6/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/faqer-EGfSzUrq-py3.6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 50\n",
    "\n",
    "trigrams = [([TOKENS[i], TOKENS[i + 1]], TOKENS[i + 2])\n",
    "            for i in range(len(TOKENS) - 2)]\n",
    "\n",
    "vocab = set(TOKENS)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "\n",
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "\n",
    "\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for context, target in trigrams:\n",
    "\n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in tensors)\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_idxs)\n",
    "\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a tensor)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "print(losses)  # The loss decreased every iteration over the training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11.0422], grad_fn=<NormBackward1>)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.PairwiseDistance()(model.embeddings(torch.tensor([word_to_ix['beauty']], dtype=torch.long)),\n",
    "model.embeddings(torch.tensor([word_to_ix['blood']], dtype=torch.long)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '/home/artkra/SOURCES/faqer/models/pickled/mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "trm = torch.load('/home/artkra/SOURCES/faqer/models/pickled/mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1428, -0.0673,  1.4930, -1.7046,  0.0919, -0.5974,  0.2349,  0.1478,\n",
       "         -1.6745, -0.2391,  1.1290, -0.2519,  1.4631,  0.2526, -0.3291, -0.5784,\n",
       "          0.4800,  1.2138,  0.7522, -1.3980, -0.0453,  1.3891,  0.2601,  1.3152,\n",
       "         -0.2578, -0.2474, -1.4981,  0.9320, -2.1634, -0.1619, -0.1663,  0.2423,\n",
       "         -1.9050,  2.5494,  0.9253,  1.2111, -0.7454,  0.1759,  0.3996, -0.4775,\n",
       "         -0.2414,  0.6097,  0.9918,  0.7516,  1.3588, -0.0250,  1.0351,  1.1524,\n",
       "         -0.7486,  0.3798]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trm.embeddings(torch.tensor([word_to_ix['привязки']], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1428, -0.0673,  1.4930, -1.7046,  0.0919, -0.5974,  0.2349,  0.1478,\n",
       "         -1.6745, -0.2391,  1.1290, -0.2519,  1.4631,  0.2526, -0.3291, -0.5784,\n",
       "          0.4800,  1.2138,  0.7522, -1.3980, -0.0453,  1.3891,  0.2601,  1.3152,\n",
       "         -0.2578, -0.2474, -1.4981,  0.9320, -2.1634, -0.1619, -0.1663,  0.2423,\n",
       "         -1.9050,  2.5494,  0.9253,  1.2111, -0.7454,  0.1759,  0.3996, -0.4775,\n",
       "         -0.2414,  0.6097,  0.9918,  0.7516,  1.3588, -0.0250,  1.0351,  1.1524,\n",
       "         -0.7486,  0.3798]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings(torch.tensor([word_to_ix['привязки']], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
